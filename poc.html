<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Document</title>
</head>

<body>

    <script>
        // getUserMedia only works over https in Chrome 47+, so we redirect to https. Also notify user if running from file.
        if (window.location.protocol == "file:") {
            alert("You seem to be running this example directly from a file. Note that these examples only work when served from a server or localhost due to canvas cross-domain restrictions.");
        } else if (window.location.hostname !== "localhost" && window.location.protocol !== "https:") {
            window.location.protocol = "https";
        }
    </script>

    <script type="text/javascript" src="./js/utils.js"></script>
    <script type="text/javascript" src="./clmtrackr.js"></script>
    <script type="text/javascript" src="../models/model_pca_20_svm.js"></script>
    <script type="text/javascript" src="./js/Stats.js"></script>
    <script type="text/javascript" src="./js/emotion_classifier.js"></script>
    <script type="text/javascript" src="./js/emotionmodel.js"></script>
    <script type="text/javascript">
        var videoInput = document.getElementById('inputVideo');
        var ctracker = new clm.tracker();
        ctracker.init();
        ctracker.start(videoInput);
    </script>
    <div id="content">
        <h2>
            <a href="https://github.com/auduno/clmtrackr">POC Webcam</a>
        </h2>

        <div id="container">
            <video id="videoel" width="400" height="300" preload="auto" loop playsinline autoplay>
            </video>
            <canvas id="overlay" width="400" height="300"></canvas>
        </div>
        <div id="emotion_container">
            <div id="emotion_icons">
                <img class="emotion_icon" id="icon1" src="./media/icon_angry.png">
                <img class="emotion_icon" id="icon2" src="./media/icon_sad.png">
                <img class="emotion_icon" id="icon3" src="./media/icon_surprised.png">
                <img class="emotion_icon" id="icon4" src="./media/icon_happy.png">
            </div>
            <div id='emotion_chart'></div>
        </div>
        <div id="controls">
            <input class="btn" type="button" value="wait, loading video" disabled="disabled" onclick="startVideo()" id="startbutton"></input>
        </div>
        <script>
            var vid = document.getElementById('videoel');
            var vid_width = vid.width;
            var vid_height = vid.height;
            var overlay = document.getElementById('overlay');
            var overlayCC = overlay.getContext('2d');

            /********** check and set up video/webcam **********/
            function enablestart() {
                var startbutton = document.getElementById('startbutton');
                startbutton.value = "start";
                startbutton.disabled = null;
            }

            function adjustVideoProportions() {
                // resize overlay and video if proportions are different
                // keep same height, just change width
                var proportion = vid.videoWidth / vid.videoHeight;
                vid_width = Math.round(vid_height * proportion);
                vid.width = vid_width;
                overlay.width = vid_width;
            }

            function gumSuccess(stream) {
                // add camera stream if getUserMedia succeeded
                if ("srcObject" in vid) {
                    vid.srcObject = stream;
                } else {
                    vid.src = (window.URL && window.URL.createObjectURL(stream));
                }
                vid.onloadedmetadata = function () {
                    adjustVideoProportions();
                    vid.play();
                }
                vid.onresize = function () {
                    adjustVideoProportions();
                    if (trackingStarted) {
                        ctrack.stop();
                        ctrack.reset();
                        ctrack.start(vid);
                    }
                }
            }

            function gumFail() {
                alert("There was some problem trying to fetch video from your webcam. If you have a webcam, please make sure to accept when the browser asks for access to your webcam.");
            }

            navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;
            window.URL = window.URL || window.webkitURL || window.msURL || window.mozURL;

            // check for camerasupport
            if (navigator.mediaDevices) {
                navigator.mediaDevices.getUserMedia({ video: true }).then(gumSuccess).catch(gumFail);
            } else if (navigator.getUserMedia) {
                navigator.getUserMedia({ video: true }, gumSuccess, gumFail);
            } else {
                alert("This demo depends on getUserMedia, which your browser does not seem to support. :(");
            }

            vid.addEventListener('canplay', enablestart, false);
            /*********** setup of emotion detection *************/
            // set eigenvector 9 and 11 to not be regularized. This is to better detect motion of the eyebrows
            pModel.shapeModel.nonRegularizedVectors.push(9);
            pModel.shapeModel.nonRegularizedVectors.push(11);
            var ctrack = new clm.tracker({ useWebGL: true });
            ctrack.init(pModel);
            var trackingStarted = false;

            function startVideo() {
                // start video
                vid.play();
                // start tracking
                ctrack.start(vid);
                trackingStarted = true;
                // start loop to draw face
                drawLoop();
            }

            seeked_emotions = ["surprised", "angry", "sad", "happy"];
            function drawLoop() {
                requestAnimFrame(drawLoop);
                var cp = ctrack.getCurrentParameters();
                var er = ec.meanPredict(cp);
                if (er) {
                    for (var i = 0; i < er.length; i++) {
                        if (er[i].value > 0.4) {
                            var user_emotion = er[i].emotion;
                            if (seeked_emotions.indexOf(user_emotion) != -1) {
                                console.log(user_emotion);
                            }
                        }
                    }
                }
            }

            delete emotionModel['disgusted'];
            delete emotionModel['fear'];
            var ec = new emotionClassifier();
            ec.init(emotionModel);
            var emotionData = ec.getBlank();
        </script>
    </div>
</body>

</html>